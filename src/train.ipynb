{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8460534f-7fd6-43be-b538-25576f9d8f58",
      "metadata": {
        "id": "8460534f-7fd6-43be-b538-25576f9d8f58"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import wandb\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torchvision.datasets import MNIST\n",
        "from lightning.pytorch import (\n",
        "    callbacks,\n",
        "    loggers,\n",
        "    Trainer,\n",
        "    utilities\n",
        ")\n",
        "\n",
        "from model import Digits\n",
        "from callbacks import DiffEarlyStopping, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "764ab7d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "root_path = Path('../')\n",
        "\n",
        "dataset = MNIST(\n",
        "    root=(root_path / 'data').as_posix(),\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=Compose([\n",
        "        ToTensor(),\n",
        "        Normalize(0.5, 0.5)\n",
        "    ])\n",
        ")\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ATxrzNMf7XhY",
      "metadata": {
        "id": "ATxrzNMf7XhY"
      },
      "outputs": [],
      "source": [
        "logging.getLogger(\"lightning.pytorch\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7b4c40ca",
      "metadata": {
        "id": "7b4c40ca"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.7 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "num_workers = os.cpu_count() - 1\n",
        "print(num_workers)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=num_workers)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=64, num_workers=num_workers)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "432b1cd2",
      "metadata": {
        "id": "432b1cd2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d30157c8",
      "metadata": {
        "id": "d30157c8"
      },
      "outputs": [],
      "source": [
        "model = Digits(\n",
        "    optimizer_name='SGD',\n",
        "    optimizer_hparams={\n",
        "        'lr': 0.001,\n",
        "        'momentum': 0.9\n",
        "    }\n",
        ")\n",
        "\n",
        "earlystopping_callbacks = [\n",
        "    DiffEarlyStopping(\n",
        "        monitor1=\"val_loss\",\n",
        "        monitor2=\"train_loss\",\n",
        "        diff_threshold=0.05, # like val_loss=0.09, train_loss=0.04\n",
        "        patience=5,\n",
        "        verbose=True\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_acc\",\n",
        "        min_delta=0.0,\n",
        "        mode='max',\n",
        "        stopping_threshold=99.99,\n",
        "        patience=5,\n",
        "        verbose=True\n",
        "    ),\n",
        "]\n",
        "\n",
        "checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filename=\"epoch={epoch}-loss={val_loss:.3f}\",\n",
        "    auto_insert_metric_name=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_top_k=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "Wvh5_S7hFo02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvh5_S7hFo02",
        "outputId": "0118779b-aa91-46db-8a3b-c07c1ac71c38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "  | Name  | Type       | Params\n",
              "-------------------------------------\n",
              "0 | model | Sequential | 322 K \n",
              "-------------------------------------\n",
              "322 K     Trainable params\n",
              "0         Non-trainable params\n",
              "322 K     Total params\n",
              "1.288     Total estimated model params size (MB)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "utilities.model_summary.ModelSummary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "155f1297",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "155f1297",
        "outputId": "cf1588b2-737e-45b5-87dc-8273d538148c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../logs/wandb/run-20230606_045928-z0wyusvs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sampath017/digits/runs/z0wyusvs' target=\"_blank\">glowing-dust-78</a></strong> to <a href='https://wandb.ai/sampath017/digits' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/sampath017/digits' target=\"_blank\">https://wandb.ai/sampath017/digits</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/sampath017/digits/runs/z0wyusvs' target=\"_blank\">https://wandb.ai/sampath017/digits/runs/z0wyusvs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "max_time =  {'minutes': 20} if torch.cuda.is_available() else {'hours': 2}\n",
        "\n",
        "log_dir = root_path/'logs'\n",
        "log_dir.mkdir(exist_ok=True)\n",
        "\n",
        "api_key = None\n",
        "try:\n",
        "    with open(root_path/'secrets.json') as f:\n",
        "        secrets = json.load(f)\n",
        "    api_key = secrets.get(\"WANDB_API_KEY\")\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "logger = loggers.WandbLogger(\n",
        "    project='digits',\n",
        "    save_dir=log_dir,\n",
        "    log_model='all',\n",
        "    # api_key=api_key\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    min_epochs=10,\n",
        "    max_epochs=50,\n",
        "    max_time=max_time,\n",
        "    logger=logger,\n",
        "    callbacks=[checkpoint_callback] + earlystopping_callbacks,\n",
        "    enable_model_summary=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zEHbqggmE5GH",
      "metadata": {
        "id": "zEHbqggmE5GH"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, train_dataloader, valid_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "xc9Xwtc2vTwt",
      "metadata": {
        "id": "xc9Xwtc2vTwt"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▁▁▁▂▆▇█████████████████████████████████</td></tr><tr><td>train_loss</td><td>█████▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▁▁▁▁▅▇██████████████████████████████████</td></tr><tr><td>val_loss</td><td>████▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>45</td></tr><tr><td>train_acc</td><td>99.02381</td></tr><tr><td>train_loss</td><td>0.03134</td></tr><tr><td>trainer/global_step</td><td>30221</td></tr><tr><td>val_acc</td><td>98.98889</td></tr><tr><td>val_loss</td><td>0.03428</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glowing-dust-78</strong> at: <a href='https://wandb.ai/sampath017/digits/runs/z0wyusvs' target=\"_blank\">https://wandb.ai/sampath017/digits/runs/z0wyusvs</a><br/>Synced 5 W&B file(s), 0 media file(s), 38 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../logs/wandb/run-20230606_045928-z0wyusvs/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "85634a30",
      "metadata": {
        "id": "85634a30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'../logs/digits/z0wyusvs/checkpoints/epoch=45-loss=0.034.ckpt'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint_callback.best_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e3f5e4",
      "metadata": {
        "id": "83e3f5e4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
